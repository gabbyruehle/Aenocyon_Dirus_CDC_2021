---
title: "Partial Proportional Odds"
date: "9/30/2021"
output: html_document
---

```{r}
#load in data
library(readr)
train <- read_csv("~/CDC2021/train.csv", 
    col_types = cols(X1 = col_skip()))
test <- read_csv("~/CDC2021/test.csv", 
    col_types = cols(X1 = col_skip()))
```

```{r}
#look at histogram of response variable and pick out where to bin the continuous variable
hist(train$tot_spent_usd[train$tot_spent_usd <6])

#bin the continuous variable by 
train$spent_ord2 <- NA
train$spent_ord2[train$tot_spent_usd == 0] <- "0"
train$spent_ord2[train$tot_spent_usd >0 & train$tot_spent_usd < 2] <- "0-2"
train$spent_ord2[train$tot_spent_usd >= 2 & train$tot_spent_usd<5] <- "2-5"
train$spent_ord2[train$tot_spent_usd > 5] <- "5+"

test$spent_ord2 <- NA
test$spent_ord2[test$tot_spent_usd == 0] <- "0"
test$spent_ord2[test$tot_spent_usd >0 & test$tot_spent_usd < 2] <- "0-2"
test$spent_ord2[test$tot_spent_usd >= 2 & test$tot_spent_usd<5] <- "2-5"
test$spent_ord2[test$tot_spent_usd > 5] <- "5+"

#look at distribution of counts of the new response variable
table(train$spent_ord2)


#create logical vector and change the ith point in vector to T/F depending on if the ith column of the dataset has a significant chi-squared association with the ordinal response variable
true_or_false <- NA
for (i in 1:89) {
  #skip column 82 which is a continuous variable and will not work in this test
  if (i != 82) {
    test <- chisq.test(table(as.factor(train[[i]]), as.factor(train[[94]])), simulate.p.value = TRUE)
    true_or_false[i] <- test$p.value < .006   
    #p-value of .006 choosen based on BIC and length of dataset n = 2268
    if(test$p.value < .006) {
      #display name of significant variable and the result of the test
      print(names(train)[i])
      print(i)
      print(test)
    }
  }
}


#change response variable to ordered factor variable in both train and test datasets
train$spent_ord2 <- factor(train$spent_ord2, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
test$spent_ord2 <- factor(test$spent_ord2, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
```


```{r}
#set variables we don't need to F and variables we do to T
true_or_false[90:93] <- FALSE
true_or_false[94] <- TRUE
true_or_false[82] <- FALSE

#subset train and test variables based on variable significance to response variable
train_significant_vars <- train[true_or_false]
test_significant_vars <- test[true_or_false]
```

```{r}
#create cumulative logit model of all predictors on the training data
library(MASS)
clogit.model <- polr(factor(spent_ord2) ~ ., 
    method = "logistic", 
    data = train_significant_vars) 
summary(clogit.model) 
```
```{r}
#get predicted probabilities from full model
pred_probs <- predict(clogit.model, newdata = test_significant_vars, type = "probs") 
head(pred_probs)
```
```{r}
#get the predicted category from full model on test dataset

#safe predicted probs of each category for each observation to test dataset
test_significant_vars$pred_probs_0 <- pred_probs[,1]
test_significant_vars$pred_probs_0to2 <- pred_probs[,2]
test_significant_vars$pred_probs_2to5 <- pred_probs[,3]
test_significant_vars$pred_probs_morethan5 <- pred_probs[,4]

#for loops find the category which is greated predicted probability for each observation of dataset
test_significant_vars$pred_category <- NA
for (i in 1:nrow(test_significant_vars)) {
  if(test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_0to2[i] &
     test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "0"
  } 
  else if(test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "0-2"
  } 
  else if(test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_0to2[i] &
     test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "2-5"
  }
  else if(test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_0to2[i]) {
    test_significant_vars$pred_category[i] <- "5+"
  }
}

#create predicted category into ordered factor variable with same levels as the response variable
test_significant_vars$pred_category <- factor(test_significant_vars$pred_category, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
#test_significant_vars$spent_ord2 <- factor(test_significant_vars$spent_ord2, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
```

```{r}
#calculate how many levels off the prediction is from the true value
test_significant_vars$number_off <- abs(as.integer(test_significant_vars$spent_ord2) - as.integer(test_significant_vars$pred_category))

#graph the number of observations that are off by 0, 1, 2, 3
library(ggplot2)
ggplot(aes(x=number_off), data = test_significant_vars) +
  geom_bar()

```


###____
#Partial Proportional Odds Model
```{r}
#print.testresult function from brant package adjusted to have more digits in p-values
print.testresult <- function(model,X2,df.v,by.var) {
  p.values = pchisq(X2,df.v,lower.tail=FALSE) 
  if(by.var){
    var.names = unlist(strsplit(as.character(formula(model))[3],split=" \\+ "))
  }else{
    var.names = names(coef(model))
  }
  # longest name
  longest.char = max(nchar(var.names))
  n.tabs = ceiling(longest.char/7)
  n.tabs = ifelse(n.tabs<2,2,n.tabs)
  cat(paste0(rep("-",28+8*n.tabs),collapse = ""),"\n")
  cat(paste0("Test for",paste0(rep("\t",n.tabs-1),collapse = ""),"X2\tdf\tprobability"),"\n")
  cat(paste0(rep("-",28+8*n.tabs),collapse = ""),"\n")
  cat(paste0("Omnibus",paste0(rep("\t",n.tabs),collapse = ""),round(X2[1],digits=2),"\t",df.v[1],"\t",round(p.values[1],digits=5)))
  cat("\n")
  for(i in 1:length(var.names)){
    name = var.names[i]
    tabs.sub = ceiling(nchar(name)/7)-1
    cat(paste0(name,paste0(rep("\t",n.tabs-tabs.sub),collapse = ""),round(X2[i+1],digits=2),"\t",df.v[i+1],"\t",round(p.values[i+1],digits=5),"\n"))
  }
  cat(paste0(rep("-",28+8*n.tabs),collapse = ""),"\n\n")
  cat("H0: Parallel Regression Assumption holds\n")
  result.matrix = matrix(c(X2, df.v, p.values), ncol = 3)
  rownames(result.matrix) = c("Omnibus", var.names)
  colnames(result.matrix) = c("X2","df","probability")
  result.matrix
}
```

```{r}
#code for brant test in brant package but unlisted table to account for large number of rows
by.var = F
m_model <- clogit.model$call
  if (is.matrix(eval.parent(m_model$data))) 
    m_model$data <- as.data.frame(data)
  m_model[-which(names(m_model) %in% c("", "formula", "data"))] <- NULL
  m_model[[1L]] <- quote(stats::model.frame)
  m_model <- eval.parent(m_model)
  Terms <- attr(m_model, "terms")
  x <- model.matrix(Terms, m_model)
  xint <- match("(Intercept)", colnames(x), nomatch = 0L)
  x <- x[, -xint, drop = FALSE]
  y <- as.numeric(model.response(m_model))
  x.variables = names(m_model)[-1]
  temp.data = data.frame(m_model, y)
  if(grepl(":",paste0(colnames(x), collapse = "")) & by.var){
    by.var = FALSE
    warning("by.var = TRUE currently not supported for interactions, setting by.var to FALSE")
  }
  
  x.factors = c()
  for (name in x.variables) {
    if (!is.numeric(m_model[, name])) {
      x.factors = c(x.factors, name)
    }
  }
  if (length(x.factors) > 0) {
    tab = table(unlist(data.frame(temp.data$y, m_model[,x.factors])))
    count0 = sum(tab == 0)
  }else {
    count0 = 0
  }
  
  
  J = max(y,na.rm=T)
  K = length(coef(clogit.model))
  for(m in 1:(J-1)){
    temp.data[[paste0("z",m)]] = ifelse(y>m,1,0)
  }
  binary.models = list()
  beta.hat = matrix(NA,nrow=J-1,ncol=K+1,byrow=T)
  var.hat = list()
  for(m in 1:(J-1)){
    mod = glm(paste0("z",m," ~ ",as.character(formula(clogit.model)[3])),data=temp.data, family="binomial")
    binary.models[[paste0("model",m)]] = mod
    beta.hat[m,] = coef(mod)
    var.hat[[m]] = vcov(mod)
  }
  
  X = cbind(1, x)
  tau = matrix(clogit.model$zeta,nrow=1,ncol=J-1,byrow=T)
  pi.hat = matrix(NA,nrow=length(clogit.model$model[,1]),ncol=J-1,byrow=T)
  for(m in 1:(J-1)){
    pi.hat[,m] = binary.models[[m]]$fitted.values
  }
  
  
  varBeta = matrix(NA,nrow = (J-1)*K, ncol = (J-1)*K)
  for(m in 1:(J-2)){
    for(l in (m+1):(J-1)){
      Wml = Matrix::Diagonal(x=pi.hat[,l] - pi.hat[,m]*pi.hat[,l])
      Wm = Matrix::Diagonal(x=pi.hat[,m] - pi.hat[,m]*pi.hat[,m])
      Wl = Matrix::Diagonal(x=pi.hat[,l] - pi.hat[,l]*pi.hat[,l])
      Xt = t(X)
      varBeta[((m-1)*K+1):(m*K),((l-1)*K+1):(l*K)] = as.matrix((solve(Xt %*% Wm %*% X)%*%(Xt %*% Wml %*% X)%*%solve(Xt %*% Wl %*% X))[-1,-1])
      varBeta[((l-1)*K+1):(l*K),((m-1)*K+1):(m*K)] = varBeta[((m-1)*K+1):(m*K),((l-1)*K+1):(l*K)]
    }
  }
  
  betaStar = c()
  for(m in 1:(J-1)){
    betaStar = c(betaStar,beta.hat[m,-1])
  }
  for(m in 1:(J-1)){
    varBeta[((m-1)*K+1):(m*K),((m-1)*K+1):(m*K)] = var.hat[[m]][-1,-1]
  }
  
  I = diag(1,K)
  E0 = diag(0,K)
  for(i in 1:(J-2)){
    for(j in 1:(J-1)){
      if(j == 1){
        temp = I
      }else if(j == i+1){
        temp = cbind(temp,-I)
      }else{
        temp = cbind(temp,E0)
      }
    }
    if(i==1){
      D = temp
    }else{
      D = rbind(D,temp)
    }
  }
  X2 = t(D%*%betaStar) %*% solve(D %*% varBeta %*% t(D)) %*% (D %*% betaStar)
  df.v = (J-2)*K
  
  if(by.var){
    combinations = getCombiCoefs(clogit.model)
    for(v in unique(combinations$var)){
      k = subset(combinations,var==v)$i
      s = c()
      df.v.temp = 0
      for(e in k){
        s = c(s,seq(from=e,to=K*(J-1),by=K))
        df.v.temp = df.v.temp + J-2
      }
      s = sort(s)
      Ds = D[,s]
      if (!is.null(dim(Ds))){
        Ds = Ds[which(!apply(Ds == 0, 1, all)), ]
      }
      if(!is.null(dim(Ds)))
        X2 = c(X2,t(Ds%*%betaStar[s]) %*% solve(Ds %*% varBeta[s,s] %*% t(Ds)) %*% (Ds %*% betaStar[s]))
      else
        X2 = c(X2,t(Ds%*%betaStar[s]) %*% solve(Ds %*% varBeta[s,s] %*% t(t(Ds))) %*% (Ds %*% betaStar[s]))
      df.v = c(df.v,df.v.temp)
    }
  }else{
    for(k in 1:K){
      s = seq(from=k,to=K*(J-1),by=K)
      Ds = D[,s]
      if (!is.null(dim(Ds))){
        Ds = Ds[which(!apply(Ds == 0, 1, all)), ]
      }
      if(!is.null(dim(Ds)))
        X2 = c(X2,t(Ds%*%betaStar[s]) %*% solve(Ds %*% varBeta[s,s] %*% t(Ds)) %*% (Ds %*% betaStar[s]))
      else
        X2 = c(X2,t(Ds%*%betaStar[s]) %*% solve(Ds %*% varBeta[s,s] %*% t(t(Ds))) %*% (Ds %*% betaStar[s]))
      df.v = c(df.v,J-2)
    }
  }
  
  result.matrix = print.testresult(clogit.model,X2,df.v,by.var)
  if(count0!=0){
    warning(paste0(count0," combinations in table(dv,ivs) do not occur. Because of that, the test results might be invalid."))
  }
  invisible(result.matrix)
```

# Variable that fail brant test: Q11_1, Q15_9
#brant test shows that these variables should not have the same slope estimate for each category of the indicated variables
#need to fit partial proportional odds model to account for these different slopes

#Partial Proportional Odds Model
```{r}
#make sure response is an ordered factor variable
train_significant_vars$spent_ord2 <- factor(train_significant_vars$spent_ord2, levels=c("0", "0-2", "2-5", "5+"), ordered=T)

#create partial proprotional odds models with all significant variables from chi-square tests and make variables that were significant in brant test have their own slope values for each category within that variable
library(VGAM)
plogit.model <- vglm(factor(spent_ord2) ~ Q5 + Q6 + Q7_4 + Q8_1 + Q8_3 + Q8_4 + Q8_7 + Q8_8 + Q9_5 + 
                       Q10_4 + Q10_7 + Q10_10 + Q10_11+ Q11_1 + Q11_3 + Q11_11 + Q11_12 + Q11_7 + 
                       Q11_8 + Q11_9 + Q15_2 + Q15_4 + Q15_5 + Q15_6 + Q15_7 + Q15_8 + Q15_9 + Q15_10 + 
                       Q15_11 + Q15_12 + Q15_14 + Q15_15 + Q15_16 + Q15_19 + Q15_21 + Q15_23 + Q18 + 
                       Q19 + Q20 + Q23 + Q28, 
    data = train_significant_vars, 
    family = cumulative(parallel = F ~ Q11_1 + Q15_9)) #parallel = FALSE for list of variables
summary(plogit.model) 
```
```{r}
#get the predicted category from partial proportional odds model on test dataset
pred_probs <- predict(plogit.model, newdata = test_significant_vars, type = "response") 
head(pred_probs)

#safe predicted probs of each category for each observation to test dataset
test_significant_vars$pred_probs_0 <- pred_probs[,1]
test_significant_vars$pred_probs_0to2 <- pred_probs[,2]
test_significant_vars$pred_probs_2to5 <- pred_probs[,3]
test_significant_vars$pred_probs_morethan5 <- pred_probs[,4]


#for loops find the category which is greated predicted probability for each observation of dataset
test_significant_vars$pred_category <- NA
for (i in 1:nrow(test_significant_vars)) {
  if(test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_0to2[i] &
     test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "0"
  } 
  else if(test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "0-2"
  } 
  else if(test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_0to2[i] &
     test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "2-5"
  }
  else if(test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_0to2[i]) {
    test_significant_vars$pred_category[i] <- "5+"
  }
}

#make predicted category variable have same factos in same order as response variable
test_significant_vars$pred_category <- factor(test_significant_vars$pred_category, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
#test_significant_vars$spent_ord2 <- factor(test_significant_vars$spent_ord2, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
```

```{r}
#calculate how many levels off the prediction is from the true value
test_significant_vars$number_off <- abs(as.integer(test_significant_vars$spent_ord2) - as.integer(test_significant_vars$pred_category))

#graph the number of observations that are off by 0, 1, 2, 3
library(ggplot2)
ggplot(aes(x=number_off), data = test_significant_vars) +
  geom_bar()

```
```{r}
#use significance level of .006
alpha.f = 0.006

#backwards elimination with p-value as evaulating criteria
back <- step4vglm(plogit.model, direction = "backward", k = qchisq(alpha.f, 1, lower.tail = FALSE))
#backwards elimination with AIC as evaulating criteria
back2 <- step4vglm(plogit.model, direction = "backward", k = 2)
#stepwise selection with AIC as evaluating criteria and lower model is the results of the backwards elimination with the p-value criteria
step <- step4vglm(plogit.model, scope = list(lower = back, upper = plogit.model), direction = "both", k = 2)
```
#backward by pvalue: factor(spent_ord2) ~ Q11_1 + Q15_2 + Q15_6 + Q15_15 + Q23
#backward by AIC/step: factor(spent_ord2) ~ Q6 + Q8_4 + Q8_7 + Q10_7 + Q11_1 + Q11_3 + Q11_11 + Q11_9 + Q15_2 + Q15_6 + Q15_8 + Q15_9 + Q15_15 + Q15_16 + Q15_23 + Q20 + Q23 + Q28

```{r}
#test if the added variables in step model improve the model compared to the back model
anova(back, step, type = 1, test = "LRT")
```

#accuracy/notch graph for step model
```{r}
#get the predicted category from step model on test dataset
pred_probs <- predict(step, newdata = test_significant_vars, type = "response") 
head(pred_probs)

#save predicted probs of each category for each observation to test dataset
test_significant_vars$pred_probs_0 <- pred_probs[,1]
test_significant_vars$pred_probs_0to2 <- pred_probs[,2]
test_significant_vars$pred_probs_2to5 <- pred_probs[,3]
test_significant_vars$pred_probs_morethan5 <- pred_probs[,4]

#for loops find the category which is greated predicted probability for each observation of dataset
test_significant_vars$pred_category <- NA
for (i in 1:nrow(test_significant_vars)) {
  if(test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_0to2[i] &
     test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_0[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "0"
  } 
  else if(test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_0to2[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "0-2"
  } 
  else if(test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_0to2[i] &
     test_significant_vars$pred_probs_2to5[i] > test_significant_vars$pred_probs_morethan5[i]) {
    test_significant_vars$pred_category[i] <- "2-5"
  }
  else if(test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_0[i] &
     test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_2to5[i] &
     test_significant_vars$pred_probs_morethan5[i] > test_significant_vars$pred_probs_0to2[i]) {
    test_significant_vars$pred_category[i] <- "5+"
  }
}

#make predicted category variable have same levels and factors as the response variable
test_significant_vars$pred_category <- factor(test_significant_vars$pred_category, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
#test_significant_vars$spent_ord2 <- factor(test_significant_vars$spent_ord2, levels=c("0", "0-2", "2-5", "5+"), ordered=T)
```

```{r}
#calculate how many levels off the prediction is from the true value
test_significant_vars$number_off <- abs(as.integer(test_significant_vars$spent_ord2) - as.integer(test_significant_vars$pred_category))

#graph the number of observations that are off by 0, 1, 2, 3
library(ggplot2)
ggplot(aes(x=number_off), data = test_significant_vars) +
  geom_bar()
```


```{r}
#summary of the back model
summary(back)
```
```{r}
#summary of the step model
summary(step)
```

```{r}
#check different models' c-statistic from area under ROC curve
library(pROC)
multiclass.roc(train_significant_vars$spent_ord2, predict(back, newdata = train_significant_vars, type = "response"))
multiclass.roc(train_significant_vars$spent_ord2, predict(step, newdata = train_significant_vars, type = "response"))
```


